"""
Credit Bond Risk - News Analyzer

LLM-powered news analysis:
- Single news analysis (sentiment, summary, entities)
- Batch processing with rate limiting
- Obligor risk digest generation
"""

import json
import logging
from datetime import datetime
from typing import Any

from pydantic import BaseModel, Field

from ..core.models import NewsItem, NewsAnalysisResult, Obligor, CreditExposure
from ..core.enums import Sentiment
from ..core.config import LLMConfig

logger = logging.getLogger(__name__)


class NewsAnalyzer:
    """
    LLMé©±åŠ¨çš„æ–°é—»åˆ†æå™¨

    Features:
    - å•ç¯‡æ–°é—»æƒ…æ„Ÿåˆ†æ
    - å…³é”®äº‹ä»¶æå–
    - å®ä½“è¯†åˆ« (å‘è¡Œäººå…³è”)
    - ä¿¡ç”¨å½±å“è¯„ä¼°
    """

    ANALYSIS_PROMPT = """åˆ†æä»¥ä¸‹ä¿¡ç”¨å€ºç›¸å…³æ–°é—»ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

æ ‡é¢˜ï¼š{title}
æ¥æºï¼š{source}
æ—¶é—´ï¼š{timestamp}
å†…å®¹ï¼š{content}

è¯·è¿”å›JSONæ ¼å¼ï¼ˆç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
{{
    "summary": "ä¸€å¥è¯æ‘˜è¦ï¼ˆä¸è¶…è¿‡50å­—ï¼‰",
    "sentiment": "POSITIVE/NEUTRAL/NEGATIVE",
    "sentiment_score": -1åˆ°1çš„æ•°å€¼ï¼ˆ-1æœ€è´Ÿé¢ï¼Œ1æœ€æ­£é¢ï¼Œ0ä¸­æ€§ï¼‰,
    "key_events": ["äº‹ä»¶1", "äº‹ä»¶2"],
    "credit_impact": "å¯¹å‘è¡Œäººä¿¡ç”¨èµ„è´¨çš„æ½œåœ¨å½±å“ï¼ˆä¸€å¥è¯ï¼‰",
    "mentioned_entities": ["å…¬å¸å1", "å…¬å¸å2"]
}}

æ³¨æ„ï¼š
1. sentiment_scoreè¦ä¸sentimentä¸€è‡´
2. å…³æ³¨è¿çº¦ã€è¯„çº§ã€èèµ„ã€ä¸šç»©ã€æ”¿ç­–ç­‰ä¿¡ç”¨ç›¸å…³äº‹ä»¶
3. mentioned_entitiesåªæå–å…¬å¸/æœºæ„åç§°"""

    DIGEST_PROMPT = """ä½œä¸ºèµ„æ·±ä¿¡ç”¨åˆ†æå¸ˆï¼Œä¸ºä»¥ä¸‹å‘è¡Œäººç”Ÿæˆé£é™©ç®€æŠ¥ã€‚

## å‘è¡Œäººä¿¡æ¯
- åç§°ï¼š{name}
- è¡Œä¸šï¼š{sector} / {sub_sector}
- åœ°åŒºï¼š{province}
- è¯„çº§ï¼š{rating} (å±•æœ›: {outlook})
- æŒä»“å¸‚å€¼ï¼š${market_value_m:.1f}M (å AUM {pct_aum:.2%})
- åŠ æƒOASï¼š{oas:.0f}bps

## è¿‘æœŸæ–°é—» ({news_count}æ¡ï¼Œè¿‡å»{days}å¤©)
{news_summary}

è¯·ç”Ÿæˆç®€æŠ¥ï¼š
1. **é£é™©æ‘˜è¦**ï¼ˆ3å¥è¯ä»¥å†…ï¼‰
2. **å…³é”®å…³æ³¨ç‚¹**ï¼ˆbullet pointsï¼Œæœ€å¤š5æ¡ï¼‰
3. **å»ºè®®è¡ŒåŠ¨**ï¼šå¢æŒè§‚å¯Ÿ / æŒæœ‰ / å‡æŒè§‚å¯Ÿ / ç«‹å³å‡æŒ
4. **é£é™©è¯„çº§**ï¼šä½/ä¸­/é«˜/æé«˜

æ ¼å¼è¦æ±‚ï¼šä½¿ç”¨Markdownï¼Œç®€æ´ä¸“ä¸šã€‚"""

    def __init__(self, config: LLMConfig | None = None):
        self.config = config or LLMConfig()
        self._client = None

    @property
    def client(self):
        """Lazy load Anthropic client"""
        if self._client is None:
            try:
                from anthropic import Anthropic
                self._client = Anthropic()
            except ImportError:
                logger.warning("anthropic package not installed, using mock client")
                self._client = MockLLMClient()
        return self._client

    def analyze_news(self, news: NewsItem) -> NewsAnalysisResult:
        """
        åˆ†æå•ç¯‡æ–°é—»

        Args:
            news: å¾…åˆ†æçš„æ–°é—»

        Returns:
            NewsAnalysisResult with sentiment, summary, etc.
        """
        prompt = self.ANALYSIS_PROMPT.format(
            title=news.title,
            source=news.source,
            timestamp=news.timestamp.strftime("%Y-%m-%d %H:%M"),
            content=news.content[:2000],  # æˆªæ–­é•¿æ–‡æœ¬
        )

        try:
            response = self.client.messages.create(
                model=self.config.model_fast,  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
                max_tokens=self.config.max_tokens_summary,
                temperature=self.config.temperature,
                messages=[{"role": "user", "content": prompt}],
            )

            # è§£æJSONå“åº”
            content = response.content[0].text
            # æå–JSONéƒ¨åˆ†
            start = content.find("{")
            end = content.rfind("}") + 1
            if start >= 0 and end > start:
                data = json.loads(content[start:end])
            else:
                raise ValueError("No valid JSON found in response")

            return NewsAnalysisResult(
                summary=data.get("summary", ""),
                sentiment=Sentiment(data.get("sentiment", "NEUTRAL")),
                sentiment_score=float(data.get("sentiment_score", 0)),
                key_events=data.get("key_events", []),
                credit_impact=data.get("credit_impact"),
                mentioned_entities=data.get("mentioned_entities", []),
            )

        except Exception as e:
            logger.error(f"News analysis failed: {e}")
            # è¿”å›é»˜è®¤ä¸­æ€§ç»“æœ
            return NewsAnalysisResult(
                summary=news.title[:50],
                sentiment=Sentiment.NEUTRAL,
                sentiment_score=0.0,
                key_events=[],
                credit_impact=None,
                mentioned_entities=[],
            )

    def generate_obligor_digest(
        self,
        obligor: Obligor,
        exposure: CreditExposure,
        news_items: list[NewsItem],
        lookback_days: int = 7,
    ) -> str:
        """
        ç”Ÿæˆå‘è¡Œäººé£é™©ç®€æŠ¥

        Args:
            obligor: å‘è¡Œäººä¿¡æ¯
            exposure: æŒä»“æ›å…‰
            news_items: è¿‘æœŸæ–°é—»
            lookback_days: æ–°é—»å›çœ‹å¤©æ•°

        Returns:
            Markdownæ ¼å¼çš„é£é™©ç®€æŠ¥
        """
        # æ ¼å¼åŒ–æ–°é—»æ‘˜è¦
        news_summary = ""
        for i, news in enumerate(news_items[:10], 1):
            sentiment_marker = {
                Sentiment.POSITIVE: "ğŸŸ¢",
                Sentiment.NEUTRAL: "âšª",
                Sentiment.NEGATIVE: "ğŸ”´",
            }.get(news.sentiment, "âšª")

            summary = news.summary or news.title[:50]
            news_summary += f"{i}. {sentiment_marker} [{news.timestamp.strftime('%m-%d')}] {summary}\n"

        if not news_summary:
            news_summary = "ï¼ˆæ— è¿‘æœŸæ–°é—»ï¼‰"

        prompt = self.DIGEST_PROMPT.format(
            name=obligor.name_cn,
            sector=obligor.sector.value,
            sub_sector=obligor.sub_sector,
            province=obligor.province or "N/A",
            rating=obligor.rating_internal.value,
            outlook=obligor.rating_outlook.value,
            market_value_m=exposure.total_market_usd / 1e6,
            pct_aum=exposure.pct_of_aum,
            oas=exposure.weighted_avg_oas or 0,
            news_count=len(news_items),
            days=lookback_days,
            news_summary=news_summary,
        )

        try:
            response = self.client.messages.create(
                model=self.config.model_primary,  # ä½¿ç”¨ä¸»åŠ›æ¨¡å‹
                max_tokens=self.config.max_tokens_analysis,
                temperature=self.config.temperature,
                messages=[{"role": "user", "content": prompt}],
            )
            return response.content[0].text

        except Exception as e:
            logger.error(f"Digest generation failed: {e}")
            return f"## {obligor.name_cn} é£é™©ç®€æŠ¥\n\n*ç”Ÿæˆå¤±è´¥: {e}*"

    def extract_entities(self, text: str) -> list[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å®ä½“ (å…¬å¸å)

        ç®€åŒ–å®ç°ï¼šä½¿ç”¨è§„åˆ™åŒ¹é…
        ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨NERæ¨¡å‹
        """
        # å¸¸è§å…¬å¸ååç¼€
        suffixes = [
            "é›†å›¢", "å…¬å¸", "æ§è‚¡", "æŠ•èµ„", "å‘å±•", "å»ºè®¾", "åŸæŠ•",
            "å›½èµ„", "èµ„äº§", "èµ„æœ¬", "é“¶è¡Œ", "ä¿é™©", "è¯åˆ¸",
        ]

        entities = []
        for suffix in suffixes:
            # ç®€å•åŒ¹é…ï¼š2-10ä¸ªå­— + åç¼€
            import re
            pattern = rf"[\u4e00-\u9fa5]{{2,10}}{suffix}"
            matches = re.findall(pattern, text)
            entities.extend(matches)

        return list(set(entities))


class BatchNewsProcessor:
    """
    æ‰¹é‡æ–°é—»å¤„ç†å™¨

    Features:
    - æ‰¹é‡åˆ†æwithé€Ÿç‡é™åˆ¶
    - ç»“æœç¼“å­˜
    - è¿›åº¦å›è°ƒ
    """

    def __init__(
        self,
        analyzer: NewsAnalyzer,
        batch_size: int = 10,
        cache_enabled: bool = True,
    ):
        self.analyzer = analyzer
        self.batch_size = batch_size
        self.cache_enabled = cache_enabled
        self._cache: dict[str, NewsAnalysisResult] = {}

    def process_batch(
        self,
        news_items: list[NewsItem],
        progress_callback: callable | None = None,
    ) -> list[NewsItem]:
        """
        æ‰¹é‡å¤„ç†æ–°é—»

        Args:
            news_items: å¾…å¤„ç†æ–°é—»åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒ (processed, total)

        Returns:
            æ›´æ–°åçš„æ–°é—»åˆ—è¡¨ (å¸¦åˆ†æç»“æœ)
        """
        total = len(news_items)
        results = []

        for i, news in enumerate(news_items):
            # æ£€æŸ¥ç¼“å­˜
            if self.cache_enabled and news.news_id in self._cache:
                analysis = self._cache[news.news_id]
            else:
                analysis = self.analyzer.analyze_news(news)
                if self.cache_enabled:
                    self._cache[news.news_id] = analysis

            # æ›´æ–°æ–°é—»å¯¹è±¡
            updated_news = news.model_copy(update={
                "summary": analysis.summary,
                "sentiment": analysis.sentiment,
                "sentiment_score": analysis.sentiment_score,
                "key_events": analysis.key_events,
            })

            # å¦‚æœæœªå…³è”å‘è¡Œäººï¼Œå°è¯•ä»å®ä½“æå–
            if not updated_news.obligor_ids and analysis.mentioned_entities:
                # TODO: å®ä½“åˆ°å‘è¡ŒäººIDçš„æ˜ å°„
                pass

            results.append(updated_news)

            # è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback(i + 1, total)

        return results

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()


class MockLLMClient:
    """Mock LLM client for testing without API"""

    class MockMessage:
        def __init__(self, text: str):
            self.text = text

    class MockResponse:
        def __init__(self, text: str):
            self.content = [MockLLMClient.MockMessage(text)]

    class MockMessages:
        def create(self, **kwargs) -> "MockLLMClient.MockResponse":
            # è¿”å›æ¨¡æ‹Ÿçš„JSONå“åº”
            mock_result = {
                "summary": "æ¨¡æ‹Ÿæ–°é—»æ‘˜è¦",
                "sentiment": "NEUTRAL",
                "sentiment_score": 0.0,
                "key_events": ["æ¨¡æ‹Ÿäº‹ä»¶"],
                "credit_impact": "å½±å“æœ‰é™",
                "mentioned_entities": ["æŸå…¬å¸"],
            }
            return MockLLMClient.MockResponse(json.dumps(mock_result))

    def __init__(self):
        self.messages = self.MockMessages()
